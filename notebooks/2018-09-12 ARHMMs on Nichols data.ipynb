{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser(\"~/Projects/zimmer\"))\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "plt.ion()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from zimmer.io import load_nichols_data\n",
    "import zimmer.plotting as zplt\n",
    "from zimmer.observations import HierarchicalIndependentAutoRegressiveObservations, HierarchicalAutoRegressiveObservations,  HierarchicalRobustAutoRegressiveObservations\n",
    "from zimmer.transitions import HierarchicalStationaryTransitions, HierarchicalRecurrentTransitions, HierarchicalRecurrentOnlyTransitions, HierarchicalNeuralNetworkRecurrentTransitions, GroupRecurrentTransitions\n",
    "from zimmer.util import cached\n",
    "\n",
    "from ssm.models import HMM\n",
    "from ssm.core import _HMM\n",
    "from ssm.init_state_distns import InitialStateDistribution\n",
    "from ssm.transitions import RecurrentTransitions, InputDrivenTransitions, StationaryTransitions, \\\n",
    "    NeuralNetworkRecurrentTransitions, RecurrentOnlyTransitions\n",
    "from ssm.observations import IndependentAutoRegressiveObservations\n",
    "\n",
    "from ssm.util import find_permutation, compute_state_overlap\n",
    "from ssm.preprocessing import pca_with_imputation, trend_filter, standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyperparameters\n",
    "D = 10   # dimensionality of continuous latent states\n",
    "M = 0    # dimensionality of input\n",
    "results_dir = \"results/nichols/2018-09-25/D{}\".format(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\"n2_1_prelet\", \n",
    "          \"n2_2_let\",\n",
    "          \"npr1_1_prelet\",\n",
    "          \"npr1_2_let\"]\n",
    "\n",
    "worms_and_groups = [(i, \"n2_1_prelet\") for i in range(11)] + \\\n",
    "                   [(i, \"n2_2_let\") for i in range(12)] + \\\n",
    "                   [(i, \"npr1_1_prelet\") for i in range(10)] + \\\n",
    "                   [(i, \"npr1_2_let\") for i in range(11)]\n",
    "worm_names = [\"{} worm {}\".format(group, i) for (i, group) in worms_and_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only including named neurons.\n",
      "73 neurons across all 44 worms\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "ys, ms, us, z_trues, z_true_key, neuron_names = load_nichols_data(worms_and_groups, worm_names, include_unnamed=False, signal=\"dff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [trend_filter(y) for y in ys]\n",
    "# ys = [standardize(y, m) for y, m in zip(ys, ms)]\n",
    "K_true = len(z_true_key)\n",
    "N = ys[0].shape[1]\n",
    "W = len(ys)\n",
    "Ts = [y.shape[0] for y in ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows blue : Quiescence\n",
      "red : Forward\n",
      "amber : Reversal\n",
      "faded green : Ventral turn\n",
      "dusty purple : Dorsal turn\n",
      "orange : undefined turn\n"
     ]
    }
   ],
   "source": [
    "for cname, zname in zip(zplt.color_names, z_true_key):\n",
    "    print(cname, \":\", zname )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical covariance from dF/F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ey = np.zeros((N,)) \n",
    "# ny = np.zeros((N))\n",
    "# EyyT = np.zeros((N, N))\n",
    "# nyyT = np.zeros((N, N))\n",
    "# for y, m in zip(ys, ms):\n",
    "#     Ey += y.sum(0)\n",
    "#     ny += m.sum(0)\n",
    "#     EyyT += y.T.dot(y)\n",
    "#     nyyT += m.T.dot(m)\n",
    "\n",
    "# # Compute the empirical covariance\n",
    "# # Cov(y) = E[(y - Ey) (y - Ey)^T]\n",
    "# #        = E[yy^T] - Ey Ey^T\n",
    "# # assert np.all(nyyT > 0)\n",
    "# EyyT /= nyyT + 1e-8\n",
    "# Ey /= ny + 1e-8\n",
    "# C = EyyT - np.outer(Ey, Ey)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(C)\n",
    "# plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction on $\\Delta$F/F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator PCA from version 0.19.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run PCA to get a 3d projection of the data\n",
    "from ssm.preprocessing import pca_with_imputation\n",
    "_pca = cached(results_dir, \"pca\")(pca_with_imputation)\n",
    "pca, xs = _pca(D, ys, ms, num_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 16))\n",
    "# lim = 6\n",
    "# w_to_plot=(0, 11, 23, 33)\n",
    "# for i,w in enumerate(w_to_plot):\n",
    "#     x = xs[w]\n",
    "#     z= z_trues[w]\n",
    "#     for d in range(1, 4):\n",
    "#         ax = plt.subplot(4, 4, (d-1) * 4 + i+1)\n",
    "#         zplt.plot_2d_continuous_states(x, z, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, d), ax=ax)\n",
    "#         plt.ylabel(\"PC {}\".format(d+1) if i == 0 else \"\")\n",
    "#         plt.title(worm_names[w])\n",
    "\n",
    "# plt.suptitle(\"Continuous Latent States (Zimmer Labels)\")\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct from PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = pca.components_.T\n",
    "# d = pca.mean_\n",
    "# y_hats = [x.dot(C.T) + d for x in xs]\n",
    "\n",
    "# n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(y_hats[0][:,n])\n",
    "# plt.plot(ys[0][:,n])\n",
    "# plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate PCA component loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# C = pca.components_.T\n",
    "# km = KMeans(12)\n",
    "# km.fit(C)\n",
    "# Cp = C[np.argsort(km.labels_)]\n",
    "# plt.imshow(Cp, vmin=-abs(C).max(), vmax=abs(C).max(), cmap=\"RdBu\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(Cp.dot(Cp.T), cmap=\"RdBu\")\n",
    "\n",
    "# for k in range(km.n_clusters):\n",
    "#     print(\"Cluster \", k)\n",
    "#     for name in [name for kn, name in zip(km.labels_, neuron_names) if kn == k]:\n",
    "#         print(name)\n",
    "        \n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train/test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 250\n",
    "train_frac = 0.7\n",
    "val_frac = 0.15\n",
    "all_ys = []\n",
    "all_xs = []\n",
    "all_ms = []\n",
    "all_us = []\n",
    "all_gs = []\n",
    "all_tags = []\n",
    "all_z_trues = []\n",
    "all_choices = []\n",
    "for tag, (y, x, m, u, tag, ztr) in enumerate(zip(ys, xs, ms, us, worms_and_groups, z_trues)):\n",
    "    T = y.shape[0]\n",
    "    C = 0\n",
    "    for start in range(0, T, chunk):\n",
    "        stop = min(start+chunk, T)\n",
    "        all_ys.append(y[start:stop])\n",
    "        all_xs.append(x[start:stop])\n",
    "        all_ms.append(m[start:stop])\n",
    "        all_us.append(u[start:stop])\n",
    "        all_z_trues.append(ztr[start:stop])\n",
    "        all_tags.append(tag)\n",
    "        C += 1\n",
    "        \n",
    "    # assign some of the data to train, val, and test\n",
    "    choices = -1 * np.ones(C)\n",
    "    choices[:int(train_frac * C)] = 0\n",
    "    choices[int(train_frac * C):int((train_frac + val_frac) * C)] = 1\n",
    "    choices[int((train_frac + val_frac) * C):] = 2\n",
    "    choices = choices[np.random.permutation(C)]\n",
    "    all_choices.append(choices)\n",
    "\n",
    "all_choices = np.concatenate(all_choices)\n",
    "get = lambda arr, chc: [x for x, c in zip(arr, all_choices) if c == chc]\n",
    "\n",
    "train_ys = get(all_ys, 0)\n",
    "train_xs = get(all_xs, 0)\n",
    "train_ms = get(all_ms, 0)\n",
    "train_us = get(all_us, 0)\n",
    "train_zs = get(all_z_trues, 0)\n",
    "# train_tags = get(all_gs, 0)\n",
    "train_tags = get(all_tags, 0)\n",
    "\n",
    "val_ys = get(all_ys, 1)\n",
    "val_xs = get(all_xs, 1)\n",
    "val_ms = get(all_ms, 1)\n",
    "val_us = get(all_us, 1)\n",
    "val_zs = get(all_z_trues, 1)\n",
    "# val_tags = get(all_gs, 1)\n",
    "val_tags = get(all_tags, 1)\n",
    "\n",
    "test_ys = get(all_ys, 2)\n",
    "test_xs = get(all_xs, 2)\n",
    "test_ms = get(all_ms, 2)\n",
    "test_us = get(all_us, 2)\n",
    "test_zs = get(all_z_trues, 2)\n",
    "# test_tags = get(all_gs, 2)\n",
    "test_tags = get(all_tags, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training chunks per worm:   \", np.bincount(train_tags))\n",
    "# print(\"Validation chunks per worm: \", np.bincount(val_tags))\n",
    "# print(\"Testing chunks per worm:    \", np.bincount(test_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_train:  986680\n",
      "D_val:    219100\n",
      "D_test:   219340\n"
     ]
    }
   ],
   "source": [
    "# Compute number of training, validation, and test entries\n",
    "D_train = sum([x.size for x in train_xs])\n",
    "D_val = sum([x.size for x in val_xs])\n",
    "D_test = sum([x.size for x in test_xs])\n",
    "\n",
    "print(\"D_train: \", D_train)\n",
    "print(\"D_val:   \", D_val)\n",
    "print(\"D_test:  \", D_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit an ARHMM to the continuous latent states, sweeping over number of discrete latent states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ks = np.arange(2, 21, step=2)\n",
    "# transitionss = [\"standard\", \"recurrent\"]\n",
    "# observationss = [\"ar\", \"robust_ar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ks = [8]\n",
    "Ks = np.arange(2, 11, step=2)\n",
    "transitionss = [\"recurrent\"]\n",
    "observationss = [\"robust_ar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_hmm(K, transitions, observations):\n",
    "    hmm = HMM(K, D, M, transitions=transitions, observations=observations)\n",
    "    lps = hmm.fit(train_xs, method=\"em\", num_em_iters=250)\n",
    "    val_ll = hmm.log_likelihood(val_xs)\n",
    "    return hmm, lps, val_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting  hmm_recurrent_robust_ar_K2\n",
      "Fitting  hmm_recurrent_robust_ar_K4\n",
      "Fitting  hmm_recurrent_robust_ar_K6\n",
      "Fitting  hmm_recurrent_robust_ar_K8\n",
      "Fitting  hmm_recurrent_robust_ar_K10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "hmm_results = {}\n",
    "for K in Ks:\n",
    "    for transitions in transitionss:\n",
    "        for observations in observationss:\n",
    "            hmm_results_name = \"hmm_{}_{}_K{}\".format(transitions, observations, K)\n",
    "            fit = cached(results_dir, hmm_results_name)(_fit_hmm)\n",
    "            \n",
    "            print(\"Fitting \", hmm_results_name)\n",
    "            hmm_results[hmm_results_name] = fit(K, transitions, observations)\n",
    "            \n",
    "with open(os.path.join(results_dir, \"hmm_results.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(hmm_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit hierarchical HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_hierarchical_hmm(K, transitions, observations, hmm):\n",
    "    # Construct the HMM components\n",
    "    init_state_distn = InitialStateDistribution(K, D, M)\n",
    "\n",
    "    transition_classes = dict(recurrent=GroupRecurrentTransitions)\n",
    "    transition_distn = transition_classes[transitions](K, D, groups, M, eta=1e-4)\n",
    "    \n",
    "    observation_classes = dict(ar=HierarchicalAutoRegressiveObservations, \n",
    "                               independent_ar=HierarchicalIndependentAutoRegressiveObservations,\n",
    "                               robust_ar=HierarchicalRobustAutoRegressiveObservations)\n",
    "    observation_distn = observation_classes[observations](K, D, worms_and_groups, M, eta=1e-4)\n",
    "    \n",
    "    # Construct the HMM\n",
    "    hhmm = _HMM(K, D, M, init_state_distn, transition_distn, observation_distn)\n",
    "\n",
    "    # Initialize with the standard HMM\n",
    "    hhmm.init_state_distn.params = copy.deepcopy(hmm.init_state_distn.params)\n",
    "    hhmm.transitions.initialize_from_standard(hmm.transitions)\n",
    "    hhmm.observations.initialize_from_standard(hmm.observations)\n",
    "\n",
    "    # Fit\n",
    "    lps = hhmm.fit(train_xs, tags=train_tags, method=\"em\", num_em_iters=250, initialize=False)\n",
    "    \n",
    "    # Validate\n",
    "    val_ll = hhmm.log_likelihood(val_xs, tags=val_tags)\n",
    "    return hhmm, lps, val_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting  hhmm_recurrent_robust_ar_K2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LP: 1471817.1:   1%|          | 3/250 [00:26<36:42,  8.92s/it]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c134bdc0c5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhhmm_results_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fit_hierarchical_hmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhhmm_results_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mhhmm_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhhmm_results_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hhmm_results.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/zimmer/zimmer/util.py\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-45fa552ac25e>\u001b[0m in \u001b[0;36m_fit_hierarchical_hmm\u001b[0;34m(K, transitions, observations, hmm)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"em\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_em_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ssm/ssm/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, datas, inputs, masks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ssm/ssm/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, datas, inputs, masks, tags, method, initialize, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fitting_methods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ssm/ssm/core.py\u001b[0m in \u001b[0;36m_fit_em\u001b[0;34m(self, datas, inputs, masks, tags, num_em_iters, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m# M step: maximize expected log joint wrt parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state_distn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ssm/ssm/transitions.py\u001b[0m in \u001b[0;36mm_step\u001b[0;34m(self, expectations, datas, inputs, masks, tags, optimizer, num_iters, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/misc/optimizers.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(grad, x0, callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/misc/optimizers.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(grad, x, callback, num_iters, step_size, b1, b2, eps)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m      \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m  \u001b[0;31m# First  moment estimate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/misc/optimizers.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, i)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0m_x0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n\u001b[1;32m     28\u001b[0m                         \"Try jacobian, elementwise_grad or holomorphic_grad.\")\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0munary_to_nary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mingrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_outgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/core.py\u001b[0m in \u001b[0;36madd_outgrads\u001b[0;34m(prev_g_flagged, g)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msparse_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/core.py\u001b[0m in \u001b[0;36msparse_add\u001b[0;34m(vs, x_prev, x_new)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msparse_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mx_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_prev\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx_prev\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmut_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVSpace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/autograd/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36mmut_add\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muntake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmut_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSparseObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmut_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hhmm_results = {}\n",
    "for K in Ks:\n",
    "    for transitions in transitionss:\n",
    "        for observations in observationss:\n",
    "            # Get the HMM results\n",
    "            hmm_results_name = \"hmm_{}_{}_K{}\".format(transitions, observations, K)\n",
    "            hmm, _, _ = hmm_results[hmm_results_name]\n",
    "            \n",
    "            # Fit the Hierarchical HMM\n",
    "            hhmm_results_name = \"hhmm_{}_{}_K{}\".format(transitions, observations, K)\n",
    "            fit = cached(results_dir, hhmm_results_name)(_fit_hierarchical_hmm)\n",
    "            print(\"Fitting \", hhmm_results_name)\n",
    "            hhmm_results[hhmm_results_name] = fit(K, transitions, observations, hmm)\n",
    "            \n",
    "with open(os.path.join(results_dir, \"hhmm_results.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(hhmm_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot train and validation likelihoods\n",
    "# plt.figure(figsize=(6, 3))\n",
    "# for transitions in transitionss:\n",
    "#     for observations in observationss:\n",
    "#         hmm_results_prefix = \"hmm_{}_{}_\".format(transitions, observations)\n",
    "#         hmm_train_lls = [hmm_results[hmm_results_prefix + \"K{}\".format(K)][1][-1] for K in Ks]\n",
    "#         plt.plot(Ks, hmm_train_lls, '-o', label=hmm_results_prefix)\n",
    "\n",
    "#         hhmm_results_prefix = \"hhmm_{}_{}_\".format(transitions, observations)\n",
    "#         hhmm_train_lls = [hhmm_results[hhmm_results_prefix + \"K{}\".format(K)][1][-1] for K in Ks]\n",
    "#         plt.plot(Ks, hhmm_train_lls, '-o', label=hhmm_results_prefix)\n",
    "\n",
    "# plt.xlabel(\"K\")\n",
    "# plt.xticks(Ks)\n",
    "# plt.ylabel(\"Training Log Prob (with prior) \")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation likelihoods\n",
    "\n",
    "# num_bars = len(transitions) * len(observations)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for transitions in transitionss:\n",
    "    for observations in observationss:\n",
    "        plt.subplot(121)\n",
    "        hmm_results_prefix = \"hmm_{}_{}_\".format(transitions, observations)\n",
    "        hmm_val_lls = [hmm_results[hmm_results_prefix + \"K{}\".format(K)][2] for K in Ks]\n",
    "        plt.plot(Ks, hmm_val_lls, '-o', label=hmm_results_prefix)\n",
    "\n",
    "        plt.subplot(122)\n",
    "        hhmm_results_prefix = \"hhmm_{}_{}_\".format(transitions, observations)\n",
    "        hhmm_val_lls = [hhmm_results[hhmm_results_prefix + \"K{}\".format(K)][2] for K in Ks]\n",
    "        plt.plot(Ks, hhmm_val_lls, '-o', label=hhmm_results_prefix)\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.xticks(Ks)\n",
    "    plt.ylabel(\"Validation LL\")\n",
    "#     plt.ylim(43000, 47000)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the HHMM to the full train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_to_all_data(model):\n",
    "    lps = model.fit(train_xs + val_xs, tags=train_tags + val_tags, method=\"em\", num_em_iters=100, initialize=False)\n",
    "    return model, lps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the HMMs\n",
    "# best_results = {}\n",
    "\n",
    "# for transitions in transitionss:\n",
    "#     for observations in observationss:\n",
    "#         hmm_results_prefix = \"hmm_{}_{}\".format(transitions, observations)\n",
    "#         hmm_val_lls = [hmm_results[hmm_results_prefix + \"_K{}\".format(K)][2] for K in Ks]\n",
    "#         best_K = Ks[np.argmax(hmm_val_lls)]\n",
    "        \n",
    "#         # Fit the best model    \n",
    "#         results_name = \"best_\" + hmm_results_prefix\n",
    "#         print(\"Fitting \", results_name, \" with K = \", best_K)\n",
    "#         fit = cached(results_dir, results_name)(_fit_to_all_data)\n",
    "#         hmm, _ = fit(hmm_results[hmm_results_prefix + \"_K{}\".format(best_K)][0])\n",
    "        \n",
    "#         # Compute the log likelihood of the test data\n",
    "#         test_ll = hmm.log_likelihood(test_xs, tags=test_tags)\n",
    "#         best_results[results_name] = (hmm, test_ll)\n",
    "        \n",
    "# # Fit the HHMMs\n",
    "# for transitions in transitionss:\n",
    "#     for observations in observationss:\n",
    "#         hhmm_results_prefix = \"hhmm_{}_{}\".format(transitions, observations)\n",
    "#         hhmm_val_lls = [hhmm_results[hhmm_results_prefix + \"_K{}\".format(K)][2] for K in Ks]\n",
    "#         best_K = Ks[np.argmax(hhmm_val_lls)]\n",
    "        \n",
    "#         # Fit the best model    \n",
    "#         results_name = \"best_\" + hhmm_results_prefix\n",
    "#         print(\"Fitting \", results_name, \" with K = \", best_K)\n",
    "#         fit = cached(results_dir, results_name)(_fit_to_all_data)\n",
    "#         hhmm, _ = fit(hhmm_results[hhmm_results_prefix + \"_K{}\".format(best_K)][0])\n",
    "        \n",
    "#         # Compute the log likelihood of the test data\n",
    "#         test_ll = hhmm.log_likelihood(test_xs, tags=test_tags)\n",
    "#         best_results[results_name] = (hhmm, test_ll)\n",
    "        \n",
    "# with open(os.path.join(results_dir, \"best_results.pkl\"), \"wb\") as f:\n",
    "#     pickle.dump(best_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot train and validation likelihoods\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# i = 0\n",
    "# for transitions in transitionss:\n",
    "#     for observations in observationss:\n",
    "#         plt.subplot(121)\n",
    "#         hmm_results_prefix = \"best_hmm_{}_{}\".format(transitions, observations)\n",
    "#         plt.bar(i, best_results[hmm_results_prefix][1], label=hmm_results_prefix)\n",
    "#         plt.ylim(300000, 330000)\n",
    "        \n",
    "#         plt.subplot(122)\n",
    "#         hhmm_results_prefix = \"best_hhmm_{}_{}\".format(transitions, observations)\n",
    "#         plt.bar(i, best_results[hhmm_results_prefix][1], label=hhmm_results_prefix)\n",
    "#         plt.ylim(300000, 330000)\n",
    "        \n",
    "#         i += 1\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hhmm, _ = best_results[\"best_hhmm_recurrent_ar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhmm, _, _ = hhmm_results['hhmm_recurrent_robust_ar_K10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhmm.K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inferred states\n",
    "z_infs = [hhmm.most_likely_states(x, tag=tag) for tag, x in zip(groups, xs)]\n",
    "hhmm.permute(find_permutation(np.concatenate(z_trues), np.concatenate(z_infs)))\n",
    "z_infs = [hhmm.most_likely_states(x, tag=tag) for tag, x in zip(groups, xs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 16))\n",
    "lim = 6\n",
    "w_to_plot=(0, 11, 23, 33)\n",
    "for i,w in enumerate(w_to_plot):\n",
    "    x = xs[w]\n",
    "    z= z_infs[w]\n",
    "    for d in range(1, 4):\n",
    "        ax = plt.subplot(4, 4, (d-1) * 4 + i+1)\n",
    "        zplt.plot_2d_continuous_states(x, z, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, d), ax=ax)\n",
    "        plt.ylabel(\"PC {}\".format(d+1) if i == 0 else \"\")\n",
    "        plt.title(worm_names[w])\n",
    "\n",
    "plt.suptitle(\"Continuous Latent States (Inferred Labels)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the overlap between inferred and true states\n",
    "K_zimmer = len(z_true_key)\n",
    "overlap = np.zeros((K_zimmer, hhmm.K), dtype=float)\n",
    "for ww in range(W):\n",
    "    for k1 in range(K_zimmer):\n",
    "        for k2 in range(hhmm.K):\n",
    "            overlap[k1, k2] += np.sum((z_trues[ww] == k1) & (z_infs[ww] == k2))\n",
    "\n",
    "# Normalize the overlap from all worms and plot\n",
    "overlap /= overlap.sum(1)[:, None]\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "gs = GridSpec(11, 12)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[:10, 1:11])\n",
    "im = ax1.imshow(overlap, vmin=0, vmax=1.0, cmap=\"Greys\", interpolation=\"nearest\", aspect=\"equal\")\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xticks([])\n",
    "ax1.set_title(\"state overlap\")\n",
    "\n",
    "lax = fig.add_subplot(gs[:10, 0])\n",
    "lax.imshow(np.arange(K_zimmer)[:, None], cmap=zplt.default_cmap, \n",
    "              vmin=0, vmax=len(zplt.default_colors) - 1, aspect=1.5)\n",
    "\n",
    "lax.set_xticks([])\n",
    "lax.set_yticks(np.arange(K_zimmer))\n",
    "lax.set_yticklabels(z_true_key)\n",
    "\n",
    "bax = fig.add_subplot(gs[10, 1:11])\n",
    "bax.imshow(np.arange(hhmm.K)[None, :], cmap=zplt.default_cmap,  aspect=\"auto\",\n",
    "           vmin=0, vmax=len(zplt.default_colors)-1)\n",
    "bax.set_xticks([])\n",
    "bax.set_yticks([])\n",
    "bax.set_xlabel(\"inferred state\")\n",
    "\n",
    "axcb = fig.add_subplot(gs[:10, 11])\n",
    "plt.colorbar(im, cax=axcb, ticks=[0, 0.5, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_model(name, model, pad=3, N_smpls=20):\n",
    "    # Get the inferred states\n",
    "    z_infs = [model.most_likely_states(x, tag=tag) for tag, x in zip(groups, xs)]\n",
    "    model.permute(find_permutation(np.concatenate(z_trues), np.concatenate(z_infs)))\n",
    "    z_infs = [model.most_likely_states(x, tag=tag) for tag, x in zip(groups, xs)]\n",
    "    \n",
    "    # Lower the noise\n",
    "    model_low_noise = copy.deepcopy(model)\n",
    "    model_low_noise.observations.inv_sigmas -= 4\n",
    "    \n",
    "    simulations = []\n",
    "\n",
    "    for g in range(4):\n",
    "        # Simulate N_smpls for this worm\n",
    "        model_simulations_g = []\n",
    "        for s in range(N_smpls):\n",
    "            print(\"Model \", name, \" Group \", g, \" sample \", s)\n",
    "            # Sample data\n",
    "            Tsmpl = Ts[g*12]\n",
    "            zpre, xpre = z_infs[g*12][-pad:], xs[g*12][-pad:]\n",
    "            zsmpl, xsmpl = model_low_noise.sample(Tsmpl, prefix=(zpre, xpre), tag=g, with_noise=True)\n",
    "\n",
    "            zsmpl = np.concatenate((zpre, zsmpl))\n",
    "            xsmpl = np.concatenate((xpre, xsmpl))\n",
    "\n",
    "            # Truncate to stable region\n",
    "            unstable = np.arange(Tsmpl+pad)[np.any(abs(xsmpl) > 10, axis=1)]\n",
    "            T_stable = np.min(np.concatenate(([Tsmpl+pad], unstable)))\n",
    "            zsmpl = zsmpl[:T_stable]\n",
    "            xsmpl = xsmpl[:T_stable]\n",
    "\n",
    "            # Project into neural space\n",
    "            ysmpl = xsmpl.dot(pca.components_) + pca.mean_\n",
    "\n",
    "            # Append\n",
    "            model_simulations_g.append((zsmpl, xsmpl, ysmpl))\n",
    "            \n",
    "        # Append this worm\n",
    "        simulations.append(model_simulations_g)\n",
    "        \n",
    "    return simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulations = {}\n",
    "for name, (model, _) in best_results.items(): \n",
    "    print(\"Simulating \", name)\n",
    "    _sim = cached(results_dir, name + \"_sim\")(simulate_model)\n",
    "    simulations[name] = _sim(name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in range(4):\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for z, x, y in simulations[\"best_hhmm_recurrent_ar\"][g][:2]:\n",
    "        zplt.plot_2d_continuous_states(x, z, ax=ax, xlims=(-6, 6), ylims=(-6, 6))\n",
    "#         plt.plot(x[:,0], x[:,1], color='k', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fit a model with inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert u into o2 and do2s\n",
    "# E[u] = 13.6678;  std[u] = 5.185\n",
    "def u_to_features(u, nlags=9):\n",
    "    o2 = (u - 13.6678) / 5.185\n",
    "    do2 = np.concatenate(([0], np.diff(o2)))\n",
    "    \n",
    "    features = [o2, do2]\n",
    "    for lag in range(nlags):\n",
    "        features.append(np.concatenate([np.zeros(lag), do2[lag:]]))\n",
    "        \n",
    "    return np.column_stack(features)\n",
    "\n",
    "train_inputs = [u_to_features(u) for u in train_us]\n",
    "val_inputs = [u_to_features(u) for u in val_us]\n",
    "test_inputs = [u_to_features(u) for u in test_us]\n",
    "M = test_inputs[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_hierarchical_hmm_with_inputs(K, transitions, observations, hmm):\n",
    "    # Construct the HMM components\n",
    "    init_state_distn = InitialStateDistribution(K, D, M)\n",
    "\n",
    "    transition_classes = dict(standard=HierarchicalStationaryTransitions,\n",
    "                              recurrent=HierarchicalRecurrentTransitions,\n",
    "                              nn_recurrent=HierarchicalNeuralNetworkRecurrentTransitions)\n",
    "    transition_distn = transition_classes[transitions](K, D, 4, M, eta=1)\n",
    "    \n",
    "    observation_classes = dict(ar=HierarchicalAutoRegressiveObservations, \n",
    "                               independent_ar=HierarchicalIndependentAutoRegressiveObservations,\n",
    "                               robust_ar=HierarchicalRobustAutoRegressiveObservations)\n",
    "    observation_distn = observation_classes[observations](K, D, 4, M, eta=1e-4)\n",
    "    \n",
    "    # Construct the HMM\n",
    "    hhmm = _HMM(K, D, M, init_state_distn, transition_distn, observation_distn)\n",
    "\n",
    "    # Initialize with the standard HMM\n",
    "    # hhmm.init_state_distn.params = copy.deepcopy(hmm.init_state_distn.params)\n",
    "    # hhmm.transitions.initialize_from_standard(hmm.transitions)\n",
    "    # hhmm.observations.initialize_from_standard(hmm.observations)\n",
    "\n",
    "    # Fit\n",
    "    lps = hhmm.fit(train_xs, inputs=train_inputs, tags=train_tags, method=\"em\", num_em_iters=250)\n",
    "    \n",
    "    # Validate\n",
    "    val_ll = hhmm.log_likelihood(val_xs, inputs=val_inputs, tags=val_tags)\n",
    "    return hhmm, lps, val_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fit = cached(results_dir, \"hhmm_recurrent_ar_K8_inputs\")(_fit_hierarchical_hmm_with_inputs)\n",
    "irhhmm, lps, val_ll = _fit(8, \"recurrent\", \"ar\", hmm_results[\"hmm_recurrent_ar_K8\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inferred states\n",
    "z_infs = [irhhmm.most_likely_states(x, tag=g) for g, x in zip(groups, xs)]\n",
    "irhhmm.permute(find_permutation(np.concatenate(z_trues), np.concatenate(z_infs)))\n",
    "z_infs = [irhhmm.most_likely_states(x, tag=g) for g, x in zip(groups, xs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_figure_1(zs, w_to_plot=(1, 12, 24, 34), overlay=True, tmin=1, tmax=17):\n",
    "    slc = slice(int(tmin*60*3), int(tmax*60*3+1))\n",
    "    tslc = np.arange(int(tmin*60*3), int(tmax*60*3+1)) / 3.0 / 60.\n",
    "\n",
    "    # Make plot\n",
    "    fig = plt.figure(figsize=(13, 8))\n",
    "    fig.patch.set_alpha(0)\n",
    "    gs = GridSpec(3, len(w_to_plot), height_ratios=[12, 4, 1])\n",
    "\n",
    "    for i, w in enumerate(w_to_plot):\n",
    "        \n",
    "        # Plot neural activity\n",
    "        ax = fig.add_subplot(gs[0, i])\n",
    "        \n",
    "        if overlay:\n",
    "            ax.imshow(zs[w][slc][None, :], \n",
    "                      vmin=0, vmax=len(zplt.default_colors)-1, \n",
    "                      cmap=zplt.default_cmap, \n",
    "                      aspect=\"auto\", \n",
    "                      extent=(tmin, tmax, -N, 1), \n",
    "                      alpha=.25)\n",
    "            \n",
    "        ax.plot(tslc, (ys[w][slc] - np.arange(N)) * ms[w][slc], '-k', lw=0.5)\n",
    "        ax.plot([6, 6], [-N, 1], '-k')\n",
    "        ax.plot([12, 12], [-N, 1], '-k')\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_yticks(-np.arange(N))\n",
    "            ax.set_yticklabels(neuron_names, fontsize=4)\n",
    "            # ax.set_ylabel(\"Observed $\\Delta$ F/F\")\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "        ax.set_ylim(-N,1)\n",
    "        ax.set_xlim(tmin, tmax)\n",
    "        ax.set_xticks([])\n",
    "        # ax.set_title(\"Worm {}\".format(w+1))\n",
    "        ax.set_title(worm_names[w])\n",
    "\n",
    "        # Plot continuous latent states\n",
    "        ax = fig.add_subplot(gs[1, i])\n",
    "        \n",
    "        if overlay:\n",
    "            ax.imshow(zs[w][slc][None, :], \n",
    "                      vmin=0, vmax=len(zplt.default_colors)-1, \n",
    "                      cmap=zplt.default_cmap, \n",
    "                      aspect=\"auto\", \n",
    "                      extent=(tmin, tmax, -D, 1), \n",
    "                      alpha=.25)\n",
    "            \n",
    "        ax.plot(tslc, (xs[w][slc]  * 0.25 - np.arange(D)), '-k', lw=0.5)\n",
    "        ax.plot([6, 6], [-D, 1], '-k')\n",
    "        ax.plot([12, 12], [-D, 1], '-k')\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_yticks(np.arange(0, -D, -1))\n",
    "            ax.set_yticklabels([\"dim {}\".format(d+1) for d in range(D)], fontsize=6)\n",
    "            # ax.set_ylabel(\"Continuous States\")\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "        ax.set_ylim(-D,1)\n",
    "\n",
    "        ax.set_xlim(tmin, tmax)\n",
    "        ax.set_xticks([])\n",
    "\n",
    "        # Plot discrete latent states\n",
    "        ax = fig.add_subplot(gs[2, i])\n",
    "        ax.imshow(zs[w][slc][None, :], vmin=0, vmax=len(zplt.default_colors)-1, cmap=zplt.default_cmap, aspect=\"auto\", extent=(tmin, tmax, 0, 1))\n",
    "        ax.plot([6, 6], [0, 1], '-k')\n",
    "        ax.plot([12, 12], [0, 1], '-k')\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks(np.arange(tmin, tmax+1))\n",
    "        ax.set_xticklabels(np.arange(tmin, tmax+1), fontsize=6)\n",
    "        ax.set_xlabel(\"time (min)\")\n",
    "\n",
    "    plt.tight_layout(pad=0.5)\n",
    "\n",
    "make_figure_1(z_infs, overlay=True)\n",
    "# make_figure_1(overlay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = abs(irhhmm.transitions.Ws).max()\n",
    "for g in range(4):\n",
    "    plt.figure()\n",
    "    plt.imshow(irhhmm.transitions.Ws[g], vmin=-lim, vmax=lim, cmap=\"RdBu\")\n",
    "    plt.colorbar()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
