{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser(\"~/Projects/zimmer\"))\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from zimmer.io import load_kato_data\n",
    "import zimmer.plotting as zplt\n",
    "from zimmer.observations import HierarchicalIndependentAutoRegressiveObservations, HierarchicalAutoRegressiveObservations \n",
    "from zimmer.transitions import HierarchicalRecurrentTransitions, HierarchicalRecurrentOnlyTransitions\n",
    "from zimmer.util import cached\n",
    "\n",
    "from ssm.models import HMM\n",
    "from ssm.core import _HMM\n",
    "from ssm.init_state_distns import InitialStateDistribution\n",
    "from ssm.transitions import RecurrentTransitions, InputDrivenTransitions, StationaryTransitions, \\\n",
    "    NeuralNetworkRecurrentTransitions, RecurrentOnlyTransitions\n",
    "from ssm.observations import IndependentAutoRegressiveObservations\n",
    "\n",
    "from ssm.util import find_permutation, compute_state_overlap\n",
    "from ssm.preprocessing import pca_with_imputation, trend_filter, standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify outputs\n",
    "results_dir = \"results/kato/2018-08-29\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only including named neurons.\n",
      "59 neurons across all 5 worms\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "ys, ms, z_trues, z_true_key, neuron_names = load_kato_data(include_unnamed=False, signal=\"dff\")\n",
    "ys = [trend_filter(y) for y in ys]\n",
    "\n",
    "\n",
    "K_true = len(z_true_key)\n",
    "N = ys[0].shape[1]\n",
    "W = len(ys)\n",
    "Ts = [y.shape[0] for y in ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 10   # dimensionality of continuous latent states\n",
    "M = 0   # dimensionality of input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction on $\\Delta$F/F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run PCA to get a 3d projection of the data\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from ssm.preprocessing import pca_with_imputation\n",
    "pca, xs = pca_with_imputation(D, ys, ms)\n",
    "# xs = [gaussian_filter1d(x, 1, axis=0) for x in xs]\n",
    "# dxs = [gaussian_filter1d(np.gradient(x, axis=0), 1, axis=0) for x in xs]\n",
    "\n",
    "lim = 1.1 * abs(np.vstack(xs)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 16))\n",
    "# for w, (x, z) in enumerate(zip(xs, z_trues)):\n",
    "#     for d in range(1, D):\n",
    "#         ax = plt.subplot(D, W, (d-1) * W + w+1)\n",
    "#         zplt.plot_2d_continuous_states(x, z, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, d), ax=ax)\n",
    "#         plt.ylabel(\"PC {}\".format(d+1) if w == 0 else \"\")\n",
    "#         plt.title(\"worm {}\".format(w+1))\n",
    "\n",
    "# plt.suptitle(\"Continuous Latent States (Zimmer Labels)\")\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train/test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunk = 250\n",
    "train_frac = 0.7\n",
    "val_frac = 0.15\n",
    "all_ys = []\n",
    "all_xs = []\n",
    "all_ms = []\n",
    "all_tags = []\n",
    "all_z_trues = []\n",
    "all_choices = []\n",
    "for tag, (y, x, m, ztr) in enumerate(zip(ys, xs, ms, z_trues)):\n",
    "    T = y.shape[0]\n",
    "    C = 0\n",
    "    for start in range(0, T, chunk):\n",
    "        stop = min(start+chunk, T)\n",
    "        all_ys.append(y[start:stop])\n",
    "        all_xs.append(x[start:stop])\n",
    "        all_ms.append(m[start:stop])\n",
    "        all_z_trues.append(ztr[start:stop])\n",
    "        all_tags.append(tag)\n",
    "        C += 1\n",
    "        \n",
    "    # assign some of the data to train, val, and test\n",
    "    choices = -1 * np.ones(C)\n",
    "    choices[:int(train_frac * C)] = 0\n",
    "    choices[int(train_frac * C):int((train_frac + val_frac) * C)] = 1\n",
    "    choices[int((train_frac + val_frac) * C):] = 2\n",
    "    choices = choices[np.random.permutation(C)]\n",
    "    all_choices.append(choices)\n",
    "\n",
    "all_choices = np.concatenate(all_choices)\n",
    "get = lambda arr, chc: [x for x, c in zip(arr, all_choices) if c == chc]\n",
    "\n",
    "train_ys = get(all_ys, 0)\n",
    "train_xs = get(all_xs, 0)\n",
    "train_ms = get(all_ms, 0)\n",
    "train_zs = get(all_z_trues, 0)\n",
    "train_tags = get(all_tags, 0)\n",
    "\n",
    "val_ys = get(all_ys, 1)\n",
    "val_xs = get(all_xs, 1)\n",
    "val_ms = get(all_ms, 1)\n",
    "val_zs = get(all_z_trues, 1)\n",
    "val_tags = get(all_tags, 1)\n",
    "\n",
    "test_ys = get(all_ys, 2)\n",
    "test_xs = get(all_xs, 2)\n",
    "test_ms = get(all_ms, 2)\n",
    "test_zs = get(all_z_trues, 2)\n",
    "test_tags = get(all_tags, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "[0, 0, 1, 1, 2, 2, 3, 3, 4, 4]\n",
      "[0, 0, 1, 1, 2, 2, 3, 3, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "print(train_tags)\n",
    "print(val_tags)\n",
    "print(test_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit an ARHMM to the continuous latent states, sweeping over number of discrete latent states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ks = np.arange(2, 21, step=2)\n",
    "transitionss = [\"recurrent\"]\n",
    "observationss = [\"ar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _fit_hmm(K, transitions, observations):\n",
    "    hmm = HMM(K, D, M, transitions=transitions, observations=observations)\n",
    "    lps = hmm.fit(train_xs, method=\"em\", num_em_iters=100)\n",
    "    val_ll = hmm.log_likelihood(val_xs)\n",
    "    return hmm, lps, val_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting  hmm_recurrent_ar_K2\n",
      "Fitting  hmm_recurrent_ar_K4\n",
      "Fitting  hmm_recurrent_ar_K6\n",
      "Iteration 0.  LP: 181209.9\n",
      "Iteration 1.  LP: 185224.4\n",
      "Iteration 2.  LP: 185984.6\n",
      "Iteration 3.  LP: 186076.7\n",
      "Iteration 4.  LP: 186045.6\n",
      "Iteration 5.  LP: 185958.0\n",
      "Iteration 6.  LP: 185923.9\n",
      "Iteration 7.  LP: 185945.2\n",
      "Iteration 8.  LP: 185994.7\n",
      "Iteration 9.  LP: 186058.3\n",
      "Iteration 10.  LP: 186079.4\n",
      "Iteration 11.  LP: 186088.5\n",
      "Iteration 12.  LP: 186156.7\n",
      "Iteration 13.  LP: 186186.9\n",
      "Iteration 14.  LP: 186221.3\n",
      "Iteration 15.  LP: 186279.3\n",
      "Iteration 16.  LP: 186357.4\n",
      "Iteration 17.  LP: 186420.9\n",
      "Iteration 18.  LP: 186473.5\n",
      "Iteration 19.  LP: 186527.6\n",
      "Iteration 20.  LP: 186558.1\n",
      "Iteration 21.  LP: 186587.5\n",
      "Iteration 22.  LP: 186620.1\n",
      "Iteration 23.  LP: 186651.6\n",
      "Iteration 24.  LP: 186676.5\n",
      "Iteration 25.  LP: 186676.8\n",
      "Iteration 26.  LP: 186653.8\n",
      "Iteration 27.  LP: 186643.0\n",
      "Iteration 28.  LP: 186596.1\n",
      "Iteration 29.  LP: 186518.8\n",
      "Iteration 30.  LP: 186497.9\n",
      "Iteration 31.  LP: 186474.2\n",
      "Iteration 32.  LP: 186461.3\n",
      "Iteration 33.  LP: 186470.0\n",
      "Iteration 34.  LP: 186470.8\n",
      "Iteration 35.  LP: 186445.9\n",
      "Iteration 36.  LP: 186422.1\n",
      "Iteration 37.  LP: 186424.9\n",
      "Iteration 38.  LP: 186409.3\n",
      "Iteration 39.  LP: 186433.5\n",
      "Iteration 40.  LP: 186433.3\n",
      "Iteration 41.  LP: 186448.3\n",
      "Iteration 42.  LP: 186450.2\n",
      "Iteration 43.  LP: 186532.6\n",
      "Iteration 44.  LP: 186599.2\n",
      "Iteration 45.  LP: 186665.9\n",
      "Iteration 46.  LP: 186690.5\n",
      "Iteration 47.  LP: 186687.0\n",
      "Iteration 48.  LP: 186678.7\n",
      "Iteration 49.  LP: 186700.8\n",
      "Iteration 50.  LP: 186752.5\n",
      "Iteration 51.  LP: 186805.1\n",
      "Iteration 52.  LP: 186883.3\n",
      "Iteration 53.  LP: 186947.1\n",
      "Iteration 54.  LP: 186991.4\n",
      "Iteration 55.  LP: 187080.4\n",
      "Iteration 56.  LP: 187155.8\n",
      "Iteration 57.  LP: 187235.6\n",
      "Iteration 58.  LP: 187336.1\n",
      "Iteration 59.  LP: 187396.6\n",
      "Iteration 60.  LP: 187458.7\n",
      "Iteration 61.  LP: 187491.1\n",
      "Iteration 62.  LP: 187513.0\n",
      "Iteration 63.  LP: 187523.5\n",
      "Iteration 64.  LP: 187504.4\n",
      "Iteration 65.  LP: 187506.5\n",
      "Iteration 66.  LP: 187485.7\n",
      "Iteration 67.  LP: 187509.8\n",
      "Iteration 68.  LP: 187530.5\n",
      "Iteration 69.  LP: 187517.5\n",
      "Iteration 70.  LP: 187509.9\n",
      "Iteration 71.  LP: 187513.0\n",
      "Iteration 72.  LP: 187511.9\n",
      "Iteration 73.  LP: 187493.6\n",
      "Iteration 74.  LP: 187498.3\n",
      "Iteration 75.  LP: 187467.3\n",
      "Iteration 76.  LP: 187479.5\n",
      "Iteration 77.  LP: 187495.8\n",
      "Iteration 78.  LP: 187475.4\n",
      "Iteration 79.  LP: 187460.8\n",
      "Iteration 80.  LP: 187467.9\n",
      "Iteration 81.  LP: 187462.4\n",
      "Iteration 82.  LP: 187461.0\n",
      "Iteration 83.  LP: 187469.6\n",
      "Iteration 84.  LP: 187445.6\n",
      "Iteration 85.  LP: 187437.5\n",
      "Iteration 86.  LP: 187422.5\n",
      "Iteration 87.  LP: 187448.1\n",
      "Iteration 88.  LP: 187425.5\n",
      "Iteration 89.  LP: 187404.5\n",
      "Iteration 90.  LP: 187411.2\n",
      "Iteration 91.  LP: 187380.5\n",
      "Iteration 92.  LP: 187391.0\n",
      "Iteration 93.  LP: 187406.5\n",
      "Iteration 94.  LP: 187406.7\n",
      "Iteration 95.  LP: 187406.1\n",
      "Iteration 96.  LP: 187426.6\n",
      "Iteration 97.  LP: 187418.5\n",
      "Iteration 98.  LP: 187421.1\n",
      "Iteration 99.  LP: 187408.3\n",
      "Fitting  hmm_recurrent_ar_K8\n",
      "Iteration 0.  LP: 187334.1\n",
      "Iteration 1.  LP: 189116.3\n",
      "Iteration 2.  LP: 189460.2\n",
      "Iteration 3.  LP: 189716.8\n",
      "Iteration 4.  LP: 190040.9\n",
      "Iteration 5.  LP: 190120.0\n"
     ]
    }
   ],
   "source": [
    "hmm_results = {}\n",
    "for K in Ks:\n",
    "    for transitions in transitionss:\n",
    "        for observations in observationss:\n",
    "            hmm_results_name = \"hmm_{}_{}_K{}\".format(transitions, observations, K)\n",
    "            fit = cached(results_dir, hmm_results_name)(_fit_hmm)\n",
    "            \n",
    "            print(\"Fitting \", hmm_results_name)\n",
    "            hmm_results[hmm_results_name] = fit(K, transitions, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit hierarchical HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _fit_hierarchical_hmm(K, transitions, observations, hmm):\n",
    "    # Construct the HMM components\n",
    "    init_state_distn = InitialStateDistribution(K, D, M)\n",
    "\n",
    "    transition_classes = dict(recurrent=HierarchicalRecurrentTransitions)\n",
    "    transition_distn = transition_classes[transitions](K, D, W, M, eta=1e-4)\n",
    "    \n",
    "    observation_classes = dict(ar=HierarchicalAutoRegressiveObservations, \n",
    "                               independent_ar=HierarchicalIndependentAutoRegressiveObservations)\n",
    "    observation_distn = observation_classes[observations](K, D, W, M, eta=1e-4)\n",
    "    \n",
    "    # Construct the HMM\n",
    "    hhmm = _HMM(K, D, M, init_state_distn, transition_distn, observation_distn)\n",
    "\n",
    "    # Initialize with the standard HMM\n",
    "    hhmm.init_state_distn.params = copy.deepcopy(hmm.init_state_distn.params)\n",
    "    hhmm.transitions.initialize_from_standard(hmm.transitions)\n",
    "    hhmm.observations.initialize_from_standard(hmm.observations)\n",
    "\n",
    "    # Fit\n",
    "    lps = hhmm.fit(train_xs, tags=train_tags, method=\"em\", num_em_iters=100, initialize=False)\n",
    "    \n",
    "    # Validate\n",
    "    val_ll = hhmm.log_likelihood(val_xs, tags=val_tags)\n",
    "    return hhmm, lps, val_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhmm_results = {}\n",
    "for K in Ks:\n",
    "    for transitions in transitionss:\n",
    "        for observations in observationss:\n",
    "            # Get the HMM results\n",
    "            hmm_results_name = \"hmm_{}_{}_K{}\".format(transitions, observations, K)\n",
    "            hmm, _, _ = hmm_results[hmm_results_name]\n",
    "            \n",
    "            # Fit the Hierarchical HMM\n",
    "            hhmm_results_name = \"hhmm_{}_{}_K{}\".format(transitions, observations, K)\n",
    "            fit = cached(results_dir, hhmm_results_name)(_fit_hierarchical_hmm)\n",
    "            print(\"Fitting \", hhmm_results_name)\n",
    "            hhmm_results[hhmm_results_name] = fit(K, transitions, observations, hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation likelihoods\n",
    "plt.figure(figsize=(6, 3))\n",
    "hmm_train_lls = [hmm_results[\"hmm_recurrent_ar_K{}\".format(K)][1][-1] for K in Ks]\n",
    "hhmm_train_lls = [hhmm_results[\"hhmm_recurrent_ar_K{}\".format(K)][1][-1] for K in Ks]\n",
    "plt.plot(Ks, hmm_train_lls, '-o', label=\"HMM\")\n",
    "plt.plot(Ks, hhmm_train_lls, '-o', label=\"HHMM\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Validation LL\")\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "hmm_val_lls = [hmm_results[\"hmm_recurrent_ar_K{}\".format(K)][2] for K in Ks]\n",
    "hhmm_val_lls = [hhmm_results[\"hhmm_recurrent_ar_K{}\".format(K)][2] for K in Ks]\n",
    "plt.plot(Ks, hmm_val_lls, '-o', label=\"HMM\")\n",
    "plt.plot(Ks, hhmm_val_lls, '-o', label=\"HHMM\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Validation LL\")\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at inferred state segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_infs = [hhmm.most_likely_states(x, tag=tag) for tag, x in enumerate(xs)]\n",
    "hhmm.permute(find_permutation(np.concatenate(z_trues), np.concatenate(z_infs)))\n",
    "z_infs = [hhmm.most_likely_states(x, tag=tag) for tag, x in enumerate(xs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(np.concatenate(z_infs), minlength=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zplt.plot_latent_trajectories_vs_time(xs, z_infs, plot_slice=(0, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "for w, (x, z) in enumerate(zip(xs, z_infs)):\n",
    "    ax = plt.subplot(1, W, w+1)\n",
    "    zplt.plot_2d_continuous_states(x, z, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, 1), ax=ax)\n",
    "    plt.ylabel(\"PC 2\" if w == 0 else \"\")\n",
    "    plt.xlabel(\"PC 1\")\n",
    "    plt.title(\"worm {}\".format(w+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "for w, (x, z) in enumerate(zip(xs, z_infs)):\n",
    "    ax = plt.subplot(1, W, w+1)\n",
    "    zplt.plot_2d_continuous_states(x, z, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, 2), ax=ax)\n",
    "    plt.ylabel(\"PC 3\" if w == 0 else \"\")\n",
    "    plt.xlabel(\"PC 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D > 3:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    for w, (x, z) in enumerate(zip(xs, z_infs)):    \n",
    "        ax = plt.subplot(1, W, w+1)\n",
    "        zplt.plot_2d_continuous_states(x, z, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, 3), ax=ax)\n",
    "        plt.ylabel(\"PC 4\" if w == 0 else \"\")\n",
    "        plt.xlabel(\"PC 1\")    \n",
    "        plt.title(\"worm {}\".format(w+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D > 4:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    for w, (x, z) in enumerate(zip(xs, z_infs)):\n",
    "        ax = plt.subplot(1, W, w+1)\n",
    "        zplt.plot_2d_continuous_states(x, z, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, 4), ax=ax)\n",
    "        plt.ylabel(\"PC 5\" if w == 0 else \"\")\n",
    "        plt.xlabel(\"PC 1\")    \n",
    "        plt.title(\"worm {}\".format(w+1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D > 5:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    for w, (x, z) in enumerate(zip(xs, z_infs)):  \n",
    "        ax = plt.subplot(1, W, w+1)\n",
    "        zplt.plot_2d_continuous_states(x, z, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, 5), ax=ax)\n",
    "        plt.ylabel(\"PC 6\" if w == 0 else \"\")\n",
    "        plt.xlabel(\"PC 1\")    \n",
    "        plt.title(\"worm {}\".format(w+1))\n",
    "\n",
    "    plt.suptitle(\"Continuous Latent States (Zimmer Labels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare inferred and manually labeled states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zplt.plot_state_overlap(z_infs, z_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to find overlap percentages\n",
    "def compute_pct_overlap(zi, ztr):\n",
    "    overlap = np.zeros((K, K_true))\n",
    "    for k in range(K):\n",
    "        overlap[k] = np.bincount(ztr[zi == k], minlength=K_true).astype(float)\n",
    "        overlap[k] /= (overlap[k].sum() + 1e-3)\n",
    "    return overlap\n",
    "\n",
    "# Find a permutation so that the bar codes look progressive\n",
    "total_overlap = compute_pct_overlap(np.concatenate(z_infs), np.concatenate(z_trues))\n",
    "overlap_perm = np.argsort(np.argmax(total_overlap, axis=1))\n",
    "\n",
    "# Helper function to plot \"barcodes\"\n",
    "def plot_overlap_barcode(ax, overlap):\n",
    "    for i,k in enumerate(overlap_perm):        \n",
    "        for ktr in range(K_true):\n",
    "            plt.bar(i, overlap[k, ktr], bottom=np.sum(overlap[k, :ktr]), color=zplt.default_colors[ktr], width=0.8)\n",
    "    ax.set_xlim(-.5, K-.5)\n",
    "    \n",
    "# Plot all overlaps as bar codes\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot the total overlap first\n",
    "ax = plt.subplot(1, W+1, 1)\n",
    "plot_overlap_barcode(ax, total_overlap)\n",
    "plt.ylabel(\"Pct of manual state\")\n",
    "plt.yticks([0, .25, .5, .75, 1], [0, 25, 50, 75, 100])\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Inferred state\")\n",
    "plt.xticks(np.arange(K), np.arange(K)+1)\n",
    "plt.title(\"All worms\")\n",
    "\n",
    "for w in range(W):\n",
    "    ax = plt.subplot(1, W+1, w+2)\n",
    "    overlap_w = compute_pct_overlap(z_infs[w], z_trues[w])\n",
    "    plot_overlap_barcode(ax, overlap_w)\n",
    "    plt.yticks([])        \n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"Inferred state\")\n",
    "    plt.xticks(np.arange(K), np.arange(K)+1)\n",
    "    plt.title(\"Worm {}\".format(w+1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print key\n",
    "for color_name, state_name in zip(zplt.color_names, z_true_key):\n",
    "    print(\"{} : {}\".format(color_name, state_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate from an HMM, reducing the dynamics noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hhmm_low_noise = copy.deepcopy(hhmm)\n",
    "hhmm_low_noise.observations.inv_sigmas -= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad = 3\n",
    "Tsmpl = Ts[0]\n",
    "i = 1\n",
    "zpre, xpre = z_infs[i][-pad:], xs[i][-pad:]\n",
    "zsmpl, xsmpl = hhmm_low_noise.sample(Tsmpl, prefix=(zpre, xpre), tag=i, with_noise=True)\n",
    "\n",
    "zfull = np.concatenate((zpre, zsmpl))\n",
    "xfull = np.concatenate((xpre, xsmpl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot(1, 2, 1, aspect=\"equal\")\n",
    "zplt.plot_2d_continuous_states(xfull, zfull, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, 1), ax=ax)\n",
    "plt.plot(xfull[pad-1,0], xfull[pad-1,1], 'k*')\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2, aspect=\"equal\")\n",
    "zplt.plot_2d_continuous_states(xfull, zfull, xlims=(-lim, lim), ylims=(-lim, lim), inds=(0, 2), ax=ax)\n",
    "plt.plot(xfull[pad-1,0], xfull[pad-1,2], 'k*')\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "ysim = xfull.dot(pca.components_) + pca.mean_\n",
    "plt.plot(np.arange(ysim.shape[0]) / 3.0, ysim - np.arange(N), '-k')\n",
    "plt.yticks(-np.arange(N), neuron_names)\n",
    "plt.ylim(-N,1)\n",
    "plt.xlim(0, ysim.shape[0] / 3.0)\n",
    "plt.xlabel(\"time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot real data for comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(np.arange(Ts[0]) / 3.0, ys[0] - np.arange(N), '-k')\n",
    "plt.yticks(-np.arange(N), neuron_names)\n",
    "plt.ylim(-N,1)\n",
    "plt.xlim(0, Ts[0] / 3.0)\n",
    "plt.xlabel(\"time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
